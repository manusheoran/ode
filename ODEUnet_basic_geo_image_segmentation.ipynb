{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ODEUnet_basic_geo_image_segmentation_unet_train_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFhG_WQlLslB",
        "colab_type": "code",
        "outputId": "e38e9879-2eb0-4511-f2d3-39a65956c02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/usuyama/pytorch-unet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-unet'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)\u001b[K\rremote: Compressing objects:  28% (2/7)\u001b[K\rremote: Compressing objects:  42% (3/7)\u001b[K\rremote: Compressing objects:  57% (4/7)\u001b[K\rremote: Compressing objects:  71% (5/7)\u001b[K\rremote: Compressing objects:  85% (6/7)\u001b[K\rremote: Compressing objects: 100% (7/7)\u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "Unpacking objects:   1% (1/55)   \rUnpacking objects:   3% (2/55)   \rUnpacking objects:   5% (3/55)   \rUnpacking objects:   7% (4/55)   \rUnpacking objects:   9% (5/55)   \rUnpacking objects:  10% (6/55)   \rUnpacking objects:  12% (7/55)   \rUnpacking objects:  14% (8/55)   \rUnpacking objects:  16% (9/55)   \rUnpacking objects:  18% (10/55)   \rUnpacking objects:  20% (11/55)   \rUnpacking objects:  21% (12/55)   \rUnpacking objects:  23% (13/55)   \rUnpacking objects:  25% (14/55)   \rUnpacking objects:  27% (15/55)   \rUnpacking objects:  29% (16/55)   \rUnpacking objects:  30% (17/55)   \rUnpacking objects:  32% (18/55)   \rUnpacking objects:  34% (19/55)   \rUnpacking objects:  36% (20/55)   \rUnpacking objects:  38% (21/55)   \rUnpacking objects:  40% (22/55)   \rUnpacking objects:  41% (23/55)   \rUnpacking objects:  43% (24/55)   \rUnpacking objects:  45% (25/55)   \rUnpacking objects:  47% (26/55)   \rUnpacking objects:  49% (27/55)   \rUnpacking objects:  50% (28/55)   \rUnpacking objects:  52% (29/55)   \rUnpacking objects:  54% (30/55)   \rUnpacking objects:  56% (31/55)   \rUnpacking objects:  58% (32/55)   \rUnpacking objects:  60% (33/55)   \rUnpacking objects:  61% (34/55)   \rUnpacking objects:  63% (35/55)   \rUnpacking objects:  65% (36/55)   \rUnpacking objects:  67% (37/55)   \rUnpacking objects:  69% (38/55)   \rUnpacking objects:  70% (39/55)   \rUnpacking objects:  72% (40/55)   \rremote: Total 55 (delta 2), reused 1 (delta 0), pack-reused 48\u001b[K\n",
            "Unpacking objects:  74% (41/55)   \rUnpacking objects:  76% (42/55)   \rUnpacking objects:  78% (43/55)   \rUnpacking objects:  80% (44/55)   \rUnpacking objects:  81% (45/55)   \rUnpacking objects:  83% (46/55)   \rUnpacking objects:  85% (47/55)   \rUnpacking objects:  87% (48/55)   \rUnpacking objects:  89% (49/55)   \rUnpacking objects:  90% (50/55)   \rUnpacking objects:  92% (51/55)   \rUnpacking objects:  94% (52/55)   \rUnpacking objects:  96% (53/55)   \rUnpacking objects:  98% (54/55)   \rUnpacking objects: 100% (55/55)   \rUnpacking objects: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCbYg_ouLyXs",
        "colab_type": "code",
        "outputId": "ed8f7d8d-4833-4c26-cb1f-dfcce11b9fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd \"/content/pytorch-unet\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_aDy6X8L0PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import helper\n",
        "import simulation\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "class SimDataset(Dataset):\n",
        "    def __init__(self, count, transform=None):\n",
        "        self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.input_images[idx]\n",
        "        mask = self.target_masks[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return [image, mask]\n",
        "\n",
        "# use the same transformations for train/val in this example\n",
        "trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
        "])\n",
        "\n",
        "train_set = SimDataset(1000, transform = trans)\n",
        "val_set = SimDataset(100, transform = trans)\n",
        "\n",
        "image_datasets = {\n",
        "    'train': train_set, 'val': val_set\n",
        "}\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmjVAMHiL2KR",
        "colab_type": "code",
        "outputId": "40a5fc34-ebad-4951-9519-106699f5b70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "for data in tqdm(dataloaders['train']):\n",
        "  inputs, labels = data[0], data[1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-30320e520602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj7QNDnoxDkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVNE3zLlxjwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_parameters(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTw2PWsEMZdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CliqxeJKM3Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(inputs.size(), labels.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsGaQBzxN3Du",
        "colab_type": "code",
        "outputId": "d2527337-67b9-4fbd-bf37-b05693d9ca2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import skimage.measure\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "!pip install git+https://github.com/rtqichen/torchdiffeq\n",
        "from torchdiffeq import odeint, odeint_adjoint\n",
        "\n",
        "MAX_NUM_STEPS = 1000  # Maximum number of steps for ODE solver\n",
        "\n",
        "class ODEBlock(nn.Module):\n",
        "    def __init__(self, odefunc, tol=10, adjoint=False):\n",
        "        \"\"\"\n",
        "        Code adapted from https://github.com/EmilienDupont/augmented-neural-odes\n",
        "        Utility class that wraps odeint and odeint_adjoint.\n",
        "        Args:\n",
        "            odefunc (nn.Module): the module to be evaluated\n",
        "            tol (float): tolerance for the ODE solver\n",
        "            adjoint (bool): whether to use the adjoint method for gradient calculation\n",
        "        \"\"\"\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.adjoint = adjoint\n",
        "        self.odefunc = odefunc\n",
        "        self.tol = tol\n",
        "\n",
        "    def forward(self, x, eval_times=None):\n",
        "        # Forward pass corresponds to solving ODE, so reset number of function\n",
        "        # evaluations counter\n",
        "        self.odefunc.nfe = 0\n",
        "\n",
        "        if eval_times is None:\n",
        "            integration_time = torch.tensor([0, 1]).float().type_as(x)\n",
        "        else:\n",
        "            integration_time = eval_times.type_as(x)\n",
        "\n",
        "        if self.adjoint:\n",
        "            out = odeint_adjoint(self.odefunc, x, integration_time,\n",
        "                                 rtol=self.tol, atol=self.tol, method='euler',\n",
        "                                 options={'max_num_steps': MAX_NUM_STEPS})\n",
        "        else:\n",
        "            out = odeint(self.odefunc, x, integration_time,\n",
        "                         rtol=self.tol, atol=self.tol, method='euler',\n",
        "                         options={'max_num_steps': MAX_NUM_STEPS})\n",
        "\n",
        "        if eval_times is None:\n",
        "            return out[1]  # Return only final time\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def trajectory(self, x, timesteps):\n",
        "        integration_time = torch.linspace(0., 1., timesteps)\n",
        "        return self.forward(x, eval_times=integration_time)\n",
        "\n",
        "\n",
        "class Conv2dTime(nn.Conv2d):\n",
        "    def __init__(self, in_channels, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Code adapted from https://github.com/EmilienDupont/augmented-neural-odes\n",
        "        Conv2d module where time gets concatenated as a feature map.\n",
        "        Makes ODE func aware of the current time step.\n",
        "        \"\"\"\n",
        "        super(Conv2dTime, self).__init__(in_channels + 1, *args, **kwargs)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        # Shape (batch_size, 1, height, width)\n",
        "        t_img = torch.ones_like(x[:, :1, :, :]) * t\n",
        "        # Shape (batch_size, channels + 1, height, width)\n",
        "        t_and_x = torch.cat([t_img, x], 1)\n",
        "        return super(Conv2dTime, self).forward(t_and_x)\n",
        "\n",
        "def get_nonlinearity(name):\n",
        "    \"\"\"Helper function to get non linearity module, choose from relu/softplus/swish/lrelu\"\"\"\n",
        "    if name == 'relu':\n",
        "        return nn.ReLU(inplace=True)\n",
        "    elif name == 'softplus':\n",
        "        return nn.Softplus()\n",
        "    elif name == 'swish':\n",
        "        return Swish(inplace=True)\n",
        "    elif name == 'lrelu':\n",
        "        return nn.LeakyReLU()\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self, inplace=False):\n",
        "        \"\"\"The Swish non linearity function\"\"\"\n",
        "        super().__init__()\n",
        "        self.inplace = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.inplace:\n",
        "            x.mul_(F.sigmoid(x))\n",
        "            return x\n",
        "        else:\n",
        "            return x * F.sigmoid(x)\n",
        "\n",
        "class ConvODEFunc(nn.Module):\n",
        "    def __init__(self, num_filters, time_dependent=False, non_linearity='relu'):\n",
        "        \"\"\"\n",
        "        Block for ConvODEUNet\n",
        "        Args:\n",
        "            num_filters (int): number of filters for the conv layers\n",
        "            time_dependent (bool): whether to concat the time as a feature map before the convs\n",
        "            non_linearity (str): which non_linearity to use (for options see get_nonlinearity)\n",
        "        \"\"\"\n",
        "        super(ConvODEFunc, self).__init__()\n",
        "        nf = num_filters\n",
        "        self.time_dependent = time_dependent\n",
        "        self.nfe = 0  # Number of function evaluations\n",
        "\n",
        "        self.norm = nn.InstanceNorm2d(nf)\n",
        "        if time_dependent:\n",
        "            self.conv1 = Conv2dTime(nf, nf, kernel_size=3, stride=1, padding=1)\n",
        "            self.conv2 = Conv2dTime(nf, nf, kernel_size=3, stride=1, padding=1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(nf, nf, kernel_size=3, stride=1, padding=1)\n",
        "            self.conv2 = nn.Conv2d(nf, nf, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.non_linearity = get_nonlinearity(non_linearity)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm(x)\n",
        "        out = self.conv1(t, out) if self.time_dependent else self.conv1(out)\n",
        "        out = self.non_linearity(out)\n",
        "        out = self.norm(out)\n",
        "        out = self.conv2(t, out) if self.time_dependent else self.conv2(out)\n",
        "        out = self.non_linearity(out)\n",
        "        return out\n",
        "\n",
        "class ConvODEUNet(nn.Module):\n",
        "    def __init__(self, num_filters, output_dim=6, time_dependent=False,\n",
        "                 non_linearity='softplus', tol=10, adjoint=False):\n",
        "        \"\"\"\n",
        "        ConvODEUNet (U-Node in paper)\n",
        "        Args:\n",
        "            num_filters (int): number of filters for first conv layer\n",
        "            output_dim (int): how many feature maps the network outputs\n",
        "            time_dependent (bool): whether to concat the time as a feature map before the convs\n",
        "            non_linearity (str): which non_linearity to use (for options see get_nonlinearity)\n",
        "            tol (float): tolerance to be used for ODE solver\n",
        "            adjoint (bool): whether to use the adjoint method to calculate the gradients\n",
        "        \"\"\"\n",
        "        super(ConvODEUNet, self).__init__()\n",
        "        nf = num_filters\n",
        "\n",
        "        self.input_1x1 = nn.Conv2d(3, nf, 1, 1)\n",
        "\n",
        "        ode_down1 = ConvODEFunc(nf, time_dependent, non_linearity)\n",
        "        self.odeblock_down1 = ODEBlock(ode_down1, tol=tol, adjoint=adjoint)\n",
        "        self.conv_down1_2 = nn.Conv2d(nf, nf*2, 1, 1)\n",
        "\n",
        "        ode_down2 = ConvODEFunc(nf*2, time_dependent, non_linearity)\n",
        "        self.odeblock_down2 = ODEBlock(ode_down2, tol=tol, adjoint=adjoint)\n",
        "        self.conv_down2_3 = nn.Conv2d(nf*2, nf*4, 1, 1)\n",
        "\n",
        "        ode_down3 = ConvODEFunc(nf*4, time_dependent, non_linearity)\n",
        "        self.odeblock_down3 = ODEBlock(ode_down3, tol=tol, adjoint=adjoint)\n",
        "        self.conv_down3_4 = nn.Conv2d(nf*4, nf*8, 1, 1)\n",
        "\n",
        "        ode_down4 = ConvODEFunc(nf*8, time_dependent, non_linearity)\n",
        "        self.odeblock_down4 = ODEBlock(ode_down4,  tol=tol, adjoint=adjoint)\n",
        "        self.conv_down4_embed = nn.Conv2d(nf*8, nf*16, 1, 1)\n",
        "\n",
        "        ode_embed = ConvODEFunc(nf*16, time_dependent, non_linearity)\n",
        "        self.odeblock_embedding = ODEBlock(ode_embed,  tol=tol, adjoint=adjoint)\n",
        "\n",
        "        self.conv_up_embed_1 = nn.Conv2d(nf*16+nf*8, nf*8, 1, 1)\n",
        "        ode_up1 = ConvODEFunc(nf*8, time_dependent, non_linearity)\n",
        "        self.odeblock_up1 = ODEBlock(ode_up1, tol=tol, adjoint=adjoint)\n",
        "\n",
        "        self.conv_up1_2 = nn.Conv2d(nf*8+nf*4, nf*4, 1, 1)\n",
        "        ode_up2 = ConvODEFunc(nf*4, time_dependent, non_linearity)\n",
        "        self.odeblock_up2 = ODEBlock(ode_up2, tol=tol, adjoint=adjoint)\n",
        "\n",
        "        self.conv_up2_3 = nn.Conv2d(nf*4+nf*2, nf*2, 1, 1)\n",
        "        ode_up3 = ConvODEFunc(nf*2, time_dependent, non_linearity)\n",
        "        self.odeblock_up3 = ODEBlock(ode_up3, tol=tol, adjoint=adjoint)\n",
        "\n",
        "        self.conv_up3_4 = nn.Conv2d(nf*2+nf, nf, 1, 1)\n",
        "        ode_up4 = ConvODEFunc(nf, time_dependent, non_linearity)\n",
        "        self.odeblock_up4 = ODEBlock(ode_up4, tol=tol, adjoint=adjoint)\n",
        "\n",
        "        self.classifier = nn.Conv2d(nf, output_dim, 1)\n",
        "\n",
        "        self.non_linearity = get_nonlinearity(non_linearity)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        x = self.non_linearity(self.input_1x1(x))\n",
        "\n",
        "        features1 = self.odeblock_down1(x)  # 512\n",
        "        x = self.non_linearity(self.conv_down1_2(features1))\n",
        "        x = nn.functional.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
        "\n",
        "        features2 = self.odeblock_down2(x)  # 256\n",
        "        x = self.non_linearity(self.conv_down2_3(features2))\n",
        "        x = nn.functional.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
        "\n",
        "        features3 = self.odeblock_down3(x)  # 128\n",
        "        x = self.non_linearity(self.conv_down3_4(features3))\n",
        "        x = nn.functional.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
        "\n",
        "        features4 = self.odeblock_down4(x)  # 64\n",
        "        x = self.non_linearity(self.conv_down4_embed(features4))\n",
        "        x = nn.functional.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
        "\n",
        "        x = self.odeblock_embedding(x)  # 32\n",
        "\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat((x, features4), dim=1)\n",
        "        x = self.non_linearity(self.conv_up_embed_1(x))\n",
        "        x = self.odeblock_up1(x)\n",
        "\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat((x, features3), dim=1)\n",
        "        x = self.non_linearity(self.conv_up1_2(x))\n",
        "        x = self.odeblock_up2(x)\n",
        "\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat((x, features2), dim=1)\n",
        "        x = self.non_linearity(self.conv_up2_3(x))\n",
        "        x = self.odeblock_up3(x)\n",
        "\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat((x, features1), dim=1)\n",
        "        x = self.non_linearity(self.conv_up3_4(x))\n",
        "        x = self.odeblock_up4(x)\n",
        "\n",
        "        pred = self.classifier(x)\n",
        "        return pred\n",
        "def plot_losses(inputs, outputs, losses, val_losses, title, nfe=None, net=None):\n",
        "    # plot statistics\n",
        "    if nfe is not None:\n",
        "        nfe[0].append(net.odeblock_down1.odefunc.nfe)\n",
        "        nfe[1].append(net.odeblock_down2.odefunc.nfe)\n",
        "        nfe[2].append(net.odeblock_down3.odefunc.nfe)\n",
        "        nfe[3].append(net.odeblock_down4.odefunc.nfe)\n",
        "        nfe[4].append(net.odeblock_embedding.odefunc.nfe)\n",
        "        nfe[5].append(net.odeblock_up1.odefunc.nfe)\n",
        "        nfe[6].append(net.odeblock_up2.odefunc.nfe)\n",
        "        nfe[7].append(net.odeblock_up3.odefunc.nfe)\n",
        "        nfe[8].append(net.odeblock_up4.odefunc.nfe)\n",
        "\n",
        "    if nfe is not None: cols = 4\n",
        "    else: cols = 3\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=cols, figsize=(15, 5))\n",
        "\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "\n",
        "    ax[0].plot(np.arange(len(losses)), losses, label=\"loss\")\n",
        "    ax[0].plot(np.arange(len(val_losses)), val_losses, label=\"val_loss\")\n",
        "\n",
        "    if nfe is not None:\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[0], label=\"down1\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[1], label=\"down2\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[2], label=\"down3\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[3], label=\"down4\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[4], label=\"embed\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[5], label=\"up1\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[6], label=\"up2\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[7], label=\"up3\")\n",
        "        ax[3].plot(np.arange(len(nfe[0])), nfe[8], label=\"up4\")\n",
        "        ax[3].legend()\n",
        "\n",
        "    outputs = torch.argmax(torch.softmax(outputs, dim=1), dim=1)[0]\n",
        "    outputs = outputs.detach().cpu()\n",
        "    outputs = outputs.numpy()\n",
        "\n",
        "    ax[0].legend()\n",
        "    ax[1].imshow(outputs)\n",
        "    ax[2].imshow(inputs.detach().cpu()[0].numpy().transpose(1, 2, 0))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rtqichen/torchdiffeq\n",
            "  Cloning https://github.com/rtqichen/torchdiffeq to /tmp/pip-req-build-etrrdwlo\n",
            "  Running command git clone -q https://github.com/rtqichen/torchdiffeq /tmp/pip-req-build-etrrdwlo\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq==0.0.1) (1.4.0)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.0.1-cp36-none-any.whl size=25884 sha256=3253b4779dee58f8f45580736215f44ce63f249e8e831cb6c9f6dd46abb1d839\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z3y6wprf/wheels/3f/76/69/01867bf3355c3bc8bae7e556b17b44c395b6cda5e76fd8ddc7\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc8SWG9WVbh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "from loss import dice_loss\n",
        "\n",
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    pred = F.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    print(\"LR\", param_group['lr'])\n",
        "\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(\"saving best model\")\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDTBLsipZ6NH",
        "colab_type": "code",
        "outputId": "1a0d9bd1-4937-4750-9562-a25bee244c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "num_class = 6\n",
        "model = ConvODEUNet(num_filters=16, output_dim=6, time_dependent=True, \n",
        "                      non_linearity='lrelu', adjoint=True, tol=10).to(device)\n",
        "\n",
        "# freeze backbone layers\n",
        "#for l in model.base_layers:\n",
        "#    for param in l.parameters():\n",
        "#        param.requires_grad = False\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/misc.py:81: UserWarning: Euler: Unexpected arguments {'max_num_steps': 1000}\n",
            "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "100%|██████████| 40/40 [00:12<00:00,  3.38it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.633481, dice: 0.988836, loss: 0.811159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.523632, dice: 0.990647, loss: 0.757140\n",
            "saving best model\n",
            "0m 13s\n",
            "Epoch 1/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.382943, dice: 0.988509, loss: 0.685726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.182511, dice: 0.987274, loss: 0.584892\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 2/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.077939, dice: 0.983461, loss: 0.530700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.69it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.033947, dice: 0.973953, loss: 0.503950\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 3/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.031016, dice: 0.899848, loss: 0.465432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.48it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.022230, dice: 0.808973, loss: 0.415602\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 4/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.023525, dice: 0.769805, loss: 0.396665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.56it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.022066, dice: 0.730337, loss: 0.376202\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 5/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.021516, dice: 0.705392, loss: 0.363454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.71it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.023206, dice: 0.676335, loss: 0.349771\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 6/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.025262, dice: 0.647101, loss: 0.336182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.32it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.026650, dice: 0.625797, loss: 0.326224\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 7/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.024424, dice: 0.586251, loss: 0.305337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.024533, dice: 0.561666, loss: 0.293100\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 8/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.023769, dice: 0.552071, loss: 0.287920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.25it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.025227, dice: 0.531126, loss: 0.278177\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 9/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.022186, dice: 0.519579, loss: 0.270882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.49it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.020268, dice: 0.507385, loss: 0.263826\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 10/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.019042, dice: 0.515063, loss: 0.267053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.021622, dice: 0.533775, loss: 0.277699\n",
            "0m 12s\n",
            "Epoch 11/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.020904, dice: 0.504338, loss: 0.262621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.67it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.021894, dice: 0.500334, loss: 0.261114\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 12/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.023492, dice: 0.475343, loss: 0.249418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.39it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.026512, dice: 0.453998, loss: 0.240255\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 13/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.023500, dice: 0.437105, loss: 0.230303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.023420, dice: 0.414446, loss: 0.218933\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 14/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.021869, dice: 0.416416, loss: 0.219142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.60it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.019815, dice: 0.410433, loss: 0.215124\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 15/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.020763, dice: 0.407519, loss: 0.214141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.020968, dice: 0.423962, loss: 0.222465\n",
            "0m 12s\n",
            "Epoch 16/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.019946, dice: 0.409535, loss: 0.214741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.55it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.019730, dice: 0.402243, loss: 0.210986\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 17/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.019903, dice: 0.400878, loss: 0.210390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.47it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.019727, dice: 0.420344, loss: 0.220035\n",
            "0m 12s\n",
            "Epoch 18/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.020255, dice: 0.463524, loss: 0.241890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.36it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.024062, dice: 0.472607, loss: 0.248334\n",
            "0m 12s\n",
            "Epoch 19/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.021047, dice: 0.407095, loss: 0.214071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.56it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.016586, dice: 0.387117, loss: 0.201851\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 20/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.33it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.016704, dice: 0.386544, loss: 0.201624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.38it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.015923, dice: 0.383382, loss: 0.199653\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 21/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.015872, dice: 0.375606, loss: 0.195739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.013860, dice: 0.373828, loss: 0.193844\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 22/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.012804, dice: 0.372510, loss: 0.192657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.51it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011099, dice: 0.374690, loss: 0.192894\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 23/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010871, dice: 0.336982, loss: 0.173926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.92it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.010454, dice: 0.325268, loss: 0.167861\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 24/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.011350, dice: 0.324590, loss: 0.167970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011216, dice: 0.318710, loss: 0.164963\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 25/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010237, dice: 0.299754, loss: 0.154996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.009897, dice: 0.306601, loss: 0.158249\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 26/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.009332, dice: 0.287522, loss: 0.148427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.44it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.009693, dice: 0.300730, loss: 0.155211\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 27/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010128, dice: 0.292574, loss: 0.151351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.29it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.010711, dice: 0.293301, loss: 0.152006\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 28/59\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010746, dice: 0.288992, loss: 0.149869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.012786, dice: 0.302851, loss: 0.157818\n",
            "0m 12s\n",
            "Epoch 29/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.011214, dice: 0.275372, loss: 0.143293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.55it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011199, dice: 0.288488, loss: 0.149843\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 30/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010701, dice: 0.265969, loss: 0.138335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.35it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.010820, dice: 0.281589, loss: 0.146205\n",
            "saving best model\n",
            "0m 12s\n",
            "Epoch 31/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010517, dice: 0.264106, loss: 0.137311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.60it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.010848, dice: 0.282233, loss: 0.146541\n",
            "0m 12s\n",
            "Epoch 32/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010562, dice: 0.265415, loss: 0.137988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.60it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011110, dice: 0.285378, loss: 0.148244\n",
            "0m 12s\n",
            "Epoch 33/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010712, dice: 0.266383, loss: 0.138547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011195, dice: 0.286262, loss: 0.148729\n",
            "0m 12s\n",
            "Epoch 34/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010675, dice: 0.266185, loss: 0.138430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.49it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011295, dice: 0.285476, loss: 0.148386\n",
            "0m 12s\n",
            "Epoch 35/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010668, dice: 0.265021, loss: 0.137845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.51it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011178, dice: 0.282973, loss: 0.147076\n",
            "0m 12s\n",
            "Epoch 36/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010596, dice: 0.265210, loss: 0.137903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.50it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011163, dice: 0.284285, loss: 0.147724\n",
            "0m 12s\n",
            "Epoch 37/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010736, dice: 0.269000, loss: 0.139868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.51it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011455, dice: 0.290171, loss: 0.150813\n",
            "0m 12s\n",
            "Epoch 38/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train: bce: 0.010730, dice: 0.271250, loss: 0.140990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val: bce: 0.011411, dice: 0.293492, loss: 0.152451\n",
            "0m 12s\n",
            "Epoch 39/59\n",
            "----------\n",
            "LR 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 1/40 [00:00<00:11,  3.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2bc2ddc7362b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-8b05f755fd46>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c69e3981e712>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_features)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mfeatures4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modeblock_down4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_down4_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c69e3981e712>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, eval_times)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_times\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mintegration_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mintegration_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i65JBfTlaPAA",
        "colab_type": "code",
        "outputId": "3ce9db52-a66d-47da-ae07-d17e765e1737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        }
      },
      "source": [
        "import math\n",
        "import torchvision.utils\n",
        "\n",
        "def reverse_transform(inp):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    inp = (inp * 255).astype(np.uint8)\n",
        "\n",
        "    return inp\n",
        "\n",
        "model.eval()   # Set model to the evaluation mode\n",
        "\n",
        "# Create another simulation dataset for test\n",
        "test_dataset = SimDataset(3, transform = trans)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
        "\n",
        "# Get the first batch\n",
        "inputs, labels = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Predict\n",
        "t=time.time()\n",
        "pred = model(inputs)\n",
        "t1=time.time()\n",
        "# The loss functions include the sigmoid function.\n",
        "pred = F.sigmoid(pred)\n",
        "te=time.time()\n",
        "print(te-t)\n",
        "pred = pred.data.cpu().numpy()\n",
        "print(pred.shape)\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
        "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
        "\n",
        "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/misc.py:81: UserWarning: Euler: Unexpected arguments {'max_num_steps': 1000}\n",
            "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.01828622817993164\n",
            "(3, 6, 192, 192)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAKvCAYAAACLTxJeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJs+MQLEmSpNn5BfRvxOXHOHkSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkzdbjxGelP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "count_parameters(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MVkTwW89drf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tol"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}